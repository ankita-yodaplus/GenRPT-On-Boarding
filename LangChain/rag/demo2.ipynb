{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f430ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Scaled Dot-Product Attention is a type of attention mechanism in machine learning. The input for this mechanism consists of queries and keys of dimension dk, and values of dimension dv. The mechanism computes the dot products of the query with all keys, then divides each by the square root of dk, and applies a softmax function to determine the weights on the values. The attention function is computed on a set of queries simultaneously, which are packed together into a matrix Q. The keys and values are also packed together into matrices K and V. The output is computed as: Attention(Q, K, V) = softmax(QKT / sqrt(dk)) * V. This mechanism is similar to dot-product attention, except for the scaling factor of 1/sqrt(dk). It is faster and more space-efficient than additive attention because it can be implemented using highly optimized matrix multiplication code. However, for larger values of dk, the dot products can grow large in magnitude, which can push the softmax function into regions where it has extremely small gradients. To counteract this effect, the dot products are scaled by 1/sqrt(dk).\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser  # âœ… Parser for text output\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough  # For chaining\n",
    "\n",
    "# 1. Load and split documents\n",
    "loader = PyPDFLoader(\"attention.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 2. Generate embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 3. Store in Milvus\n",
    "milvus_vectorstore = Milvus.from_documents(\n",
    "    documents[:30],\n",
    "    embedding,\n",
    "    connection_args={\n",
    "        \"host\": \"localhost\",  # or your IP\n",
    "        \"port\": \"19530\",\n",
    "    },\n",
    "    collection_name=\"attention_docs\"\n",
    ")\n",
    "\n",
    "# 4. Prepare the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "# 5. Prepare the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "# 6. Create retriever\n",
    "retriever = milvus_vectorstore.as_retriever()\n",
    "\n",
    "# 7. Define a step to fetch context from retriever\n",
    "def retrieve_context(inputs):\n",
    "    docs = retriever.invoke(inputs[\"input\"])\n",
    "    return {\"context\": \"\\n\\n\".join([doc.page_content for doc in docs]), \"input\": inputs[\"input\"]}\n",
    "\n",
    "# 8. Create output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 9. Chain: input -> retrieve -> format prompt -> LLM -> parse\n",
    "chain = (\n",
    "    RunnableLambda(retrieve_context) |\n",
    "    prompt |\n",
    "    llm |\n",
    "    parser\n",
    ")\n",
    "\n",
    "# 10. Run the chain\n",
    "response = chain.invoke({\"input\": \"Scaled Dot-Product Attention\"})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
