{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ac7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8530b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e3e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load and Split LangSmith Docs\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dceda250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Store in Milvus Vector Store\n",
    "vectordb = Milvus.from_documents(\n",
    "    documents,\n",
    "    OpenAIEmbeddings(),\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    collection_name=\"langsmith_docs\"\n",
    ")\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55119481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LangSmith Retriever Tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"langsmith_search\",\n",
    "    description=\"Use this tool to search LangSmith documentation. Always use it for LangSmith-related questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c9dc01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c24b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Wikipedia Tool\n",
    "wiki_tool = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b954588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Arxiv Tool\n",
    "arxiv_tool = ArxivQueryRun(\n",
    "    api_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dbfcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Unified Tool List\n",
    "tools = [retriever_tool, wiki_tool, arxiv_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e9eaff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='langsmith_search', description='Use this tool to search LangSmith documentation. Always use it for LangSmith-related questions.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000203FEC80E00>, retriever=VectorStoreRetriever(tags=['Milvus', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.milvus.Milvus object at 0x00000203FF5B5FA0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000203FEC80F40>, retriever=VectorStoreRetriever(tags=['Milvus', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.milvus.Milvus object at 0x00000203FF5B5FA0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\ankit\\\\OneDrive\\\\Desktop\\\\GenRPT-On-Boarding\\\\LangChain\\\\langchain-env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2f933fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Custom Prompt for RAG Tools Agent\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     SystemMessage(\n",
    "#         content=(\n",
    "#             \"You are a helpful assistant that uses tools to retrieve information.\\n\"\n",
    "#             \"Always try to use the tools when the input is about LangSmith, Wikipedia topics, or academic papers.\\n\"\n",
    "#             \"Use retrieved information to answer. If unsure, say 'I don't know'.\"\n",
    "#         )\n",
    "#     ),\n",
    "#     HumanMessage(content=\"{input}\"),\n",
    "#     MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant that uses tools to retrieve information. \"\n",
    "     \"Always try to use the tools when the input is about LangSmith, Wikipedia topics, or academic papers. \"\n",
    "     \"Use retrieved information to answer. If unsure, say 'I don't know'.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankit\\OneDrive\\Desktop\\GenRPT-On-Boarding\\LangChain\\langchain-env\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain import hub\n",
    "# # Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the LLM Agent\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7469059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000203EEBAD8A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a helpful assistant that uses tools to retrieve information. Always try to use the tools when the input is about LangSmith, Wikipedia topics, or academic papers. Use retrieved information to answer. If unsure, say 'I don't know'.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000203A44B1D90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002038C0C4B60>, root_client=<openai.OpenAI object at 0x00000203A44B2DB0>, root_async_client=<openai.AsyncOpenAI object at 0x00000203A44B0080>, model_name='gpt-4', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Use this tool to search LangSmith documentation. Always use it for LangSmith-related questions.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='langsmith_search', description='Use this tool to search LangSmith documentation. Always use it for LangSmith-related questions.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000203FEC80E00>, retriever=VectorStoreRetriever(tags=['Milvus', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.milvus.Milvus object at 0x00000203FF5B5FA0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000203FEC80F40>, retriever=VectorStoreRetriever(tags=['Milvus', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.milvus.Milvus object at 0x00000203FF5B5FA0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\ankit\\\\OneDrive\\\\Desktop\\\\GenRPT-On-Boarding\\\\LangChain\\\\langchain-env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "940f3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "\n",
      "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceChangelogCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform designed for building production-grade Language Learning Model (LLM) applications. It provides tools for close monitoring and evaluation of your application, enabling you to ship quickly and with confidence. \n",
      "\n",
      "Key features of LangSmith include:\n",
      "\n",
      "1. **Observability**: LangSmith offers LLM-native observability, which allows you to gain meaningful insights from your application. This is particularly important for LLM applications, which are non-deterministic by nature and can produce unexpected results, making them more challenging to debug. LangSmith's observability features support all stages of application development, from prototyping to beta testing and production.\n",
      "\n",
      "2. **Evaluation**: LangSmith allows you to evaluate your application over production traffic, score application performance, and get human feedback on your data.\n",
      "\n",
      "3. **Prompt Engineering**: LangSmith provides tools for iterating on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "LangSmith is framework-agnostic and can be used with or without LangChain's open source frameworks langchain and langgraph. If you are using either of these, you can enable LangSmith tracing with a single environment variable. \n",
      "\n",
      "For more information, you can refer to the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "LangSmith Response:\n",
      " {'input': 'Tell me about LangSmith', 'output': \"LangSmith is a platform designed for building production-grade Language Learning Model (LLM) applications. It provides tools for close monitoring and evaluation of your application, enabling you to ship quickly and with confidence. \\n\\nKey features of LangSmith include:\\n\\n1. **Observability**: LangSmith offers LLM-native observability, which allows you to gain meaningful insights from your application. This is particularly important for LLM applications, which are non-deterministic by nature and can produce unexpected results, making them more challenging to debug. LangSmith's observability features support all stages of application development, from prototyping to beta testing and production.\\n\\n2. **Evaluation**: LangSmith allows you to evaluate your application over production traffic, score application performance, and get human feedback on your data.\\n\\n3. **Prompt Engineering**: LangSmith provides tools for iterating on prompts, with automatic version control and collaboration features.\\n\\nLangSmith is framework-agnostic and can be used with or without LangChain's open source frameworks langchain and langgraph. If you are using either of these, you can enable LangSmith tracing with a single environment variable. \\n\\nFor more information, you can refer to the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\"}\n"
     ]
    }
   ],
   "source": [
    "# 11. Run Agent Queries\n",
    "response1 = agent_executor.invoke({\"input\": \"Tell me about LangSmith\"})\n",
    "print(\"\\nLangSmith Response:\\n\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13cbaf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allo\u001b[0m\u001b[32;1m\u001b[1;3mThe paper titled \"Heat-bath random walks with Markov bases\" was authored by Caprice Stanley and Tobias Windisch. It was published on May 26, 2016. The paper studies graphs on lattice points whose edges come from a finite set.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Arxiv Paper Response:\n",
      " {'input': \"What's the paper 1605.08386 about?\", 'output': 'The paper titled \"Heat-bath random walks with Markov bases\" was authored by Caprice Stanley and Tobias Windisch. It was published on May 26, 2016. The paper studies graphs on lattice points whose edges come from a finite set.'}\n"
     ]
    }
   ],
   "source": [
    "response2 = agent_executor.invoke({\"input\": \"What's the paper 1605.08386 about?\"})\n",
    "print(\"\\nArxiv Paper Response:\\n\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccadf940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Eiffel Tower'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Eiffel Tower\n",
      "Summary: The Eiffel Tower (  EYE-fəl; French: Tour Eiffel [tuʁ ɛfɛl] ) is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave \u001b[0m\u001b[32;1m\u001b[1;3mThe Eiffel Tower is a wrought-iron lattice tower located on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Wikipedia Response:\n",
      " {'input': 'Tell me about the Eiffel Tower', 'output': 'The Eiffel Tower is a wrought-iron lattice tower located on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.'}\n"
     ]
    }
   ],
   "source": [
    "response3 = agent_executor.invoke({\"input\": \"Tell me about the Eiffel Tower\"})\n",
    "print(\"\\nWikipedia Response:\\n\", response3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
